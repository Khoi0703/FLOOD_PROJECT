from dagster import asset
import pandas as pd
import torch
import numpy as np
from assets.preprocessing import parse_list_string_to_2d_array
from sklearn.preprocessing import StandardScaler

@asset
def predict_yenbai(training, yenbai_rain: pd.DataFrame) -> pd.DataFrame:
    model = training["model"]
    device = training["device"]
    model.eval()

    # === Load d·ªØ li·ªáu m·ªõi ƒë·ªÉ predict ===
    df = pd.read_csv("data/final/yenbai_rainfall.csv")

    # Backup b·∫£n g·ªëc ch∆∞a chu·∫©n h√≥a ƒë·ªÉ xu·∫•t CSV
    df_original = df.copy()

    # N·∫øu thi·∫øu flood_values, t·∫°o dummy
    if "flood_values" not in df.columns:
        df["flood_values"] = [[0.0] * 1600] * len(df)

    # Parse height_values & flood_values v·ªÅ 2D 40x40
    df["height_values"] = df["height_values"].apply(lambda s: parse_list_string_to_2d_array(s, 40, 40))
    df["flood_values"] = df["flood_values"].apply(lambda s: parse_list_string_to_2d_array(s, 40, 40))

    # === D√πng ƒë√∫ng scalar features nh∆∞ l√∫c training ===
    required_features = [
        "square_center_lat", "square_center_lon",
        "rainfall_3d", "rainfall_7d", "rainfall_1m",
        "permanent_water", "water_presence"
    ]
    for col in required_features:
        if col not in df.columns:
            raise ValueError(f"‚ùå Thi·∫øu c·ªôt '{col}' trong yenbai_final.csv")

    # Chu·∫©n h√≥a scalar features ƒë·ªÉ ƒë∆∞a v√†o model (KH√îNG ghi ra file)
    scaler = StandardScaler()
    df_scaled = df[required_features].copy()
    df_scaled = scaler.fit_transform(df_scaled)
    scalar_tensor = torch.tensor(df_scaled, dtype=torch.float32)

    # X·ª≠ l√Ω height_values
    spatial_np = torch.tensor([h for h in df["height_values"].values], dtype=torch.float32).unsqueeze(1)

    # Dummy edge_index n·∫øu kh√¥ng c√≥ k·∫øt n·ªëi
    num_nodes = len(df)
    edge_index = torch.empty((2, 0), dtype=torch.long)

    # === Predict ===
    with torch.no_grad():
        pred = model(spatial_np.to(device), scalar_tensor.to(device), edge_index.to(device))
        pred_np = pred.cpu().numpy().reshape(-1, 40, 40)
        df["pred_flood_values"] = [pred_np[i].tolist() for i in range(num_nodes)]

    # === T√≠nh t·ªïng ƒë·ªô ng·∫≠p (d√πng ReLU ƒë·ªÉ tr√°nh √¢m) ===
    df["pred_flood_score"] = df["pred_flood_values"].apply(
        lambda arr: np.clip(np.array(arr), 0, None).sum()
    )

    # === In Top 10 v√πng c√≥ ƒë·ªô ng·∫≠p cao nh·∫•t ===
    top10 = df_original.copy()
    top10["pred_flood_score"] = df["pred_flood_score"]
    top10_display = top10[[
        "big_square_id" if "big_square_id" in top10.columns else None,
        "square_center_lat", "square_center_lon", "pred_flood_score"
    ]].dropna(axis=1).sort_values(by="pred_flood_score", ascending=False).head(10)
    print("üåä Top 10 khu v·ª±c d·ª± ƒëo√°n c√≥ ƒë·ªô ng·∫≠p cao nh·∫•t:")
    print(top10_display)

    # === Xu·∫•t CSV s·∫°ch, gi·ªØ l·∫°i d·ªØ li·ªáu g·ªëc ch∆∞a chu·∫©n h√≥a ===
    output_cols = [
        "big_square_id" if "big_square_id" in df_original.columns else None,
        "square_center_lat", "square_center_lon",
        "rainfall_3d", "rainfall_7d", "rainfall_1m",
        "permanent_water", "water_presence",
        "pred_flood_score"
    ]
    output_cols = [col for col in output_cols if col is not None]
    df_output = df_original.copy()
    df_output["pred_flood_score"] = df["pred_flood_score"]
    df_output.to_csv("data/final/yenbai_predictions_clean.csv", index=False)

    return df
