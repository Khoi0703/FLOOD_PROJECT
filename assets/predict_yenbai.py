from dagster import asset
import pandas as pd
import torch
import numpy as np
from assets.preprocessing import parse_list_string_to_2d_array
from sklearn.preprocessing import StandardScaler

@asset
def predict_yenbai(training, yenbai_rain: pd.DataFrame) -> pd.DataFrame:
    model = training["model"]
    device = training["device"]
    model.eval()

    # === Load dá»¯ liá»‡u má»›i Ä‘á»ƒ predict ===
    df = pd.read_csv("data/final/yenbai_rainfall.csv")

    # Backup báº£n gá»‘c chÆ°a chuáº©n hÃ³a Ä‘á»ƒ xuáº¥t CSV
    df_original = df.copy()

    # Náº¿u thiáº¿u flood_values, táº¡o dummy
    if "flood_values" not in df.columns:
        df["flood_values"] = [[0.0] * 1600] * len(df)

    # Parse height_values & flood_values vá» 2D 40x40
    df["height_values"] = df["height_values"].apply(lambda s: parse_list_string_to_2d_array(s, 40, 40))
    df["flood_values"] = df["flood_values"].apply(lambda s: parse_list_string_to_2d_array(s, 40, 40))

    # === DÃ¹ng Ä‘Ãºng scalar features vÃ  scaler nhÆ° lÃºc training ===
    required_features = training.get("scalar_features", [
        "square_center_lat", "square_center_lon",
        "rainfall_3d", "rainfall_7d", "rainfall_1m",
        "permanent_water", "water_presence"
    ])  # Báº¯t buá»™c pháº£i cÃ³, khÃ´ng fallback máº·c Ä‘á»‹nh!
    missing = [col for col in required_features if col not in df.columns]
    if missing:
        print(f"[WARNING] CÃ¡c cá»™t sau bá»‹ thiáº¿u trong yenbai_final.csv, sáº½ Ä‘iá»n 0: {missing}")
        for col in missing:
            df[col] = 0.0

    # DÃ¹ng láº¡i scaler Ä‘Ã£ fit tá»« training, khÃ´ng fit láº¡i!
    scaler = training["scaler"]
    df_scaled = scaler.transform(df[required_features])
    scalar_tensor = torch.tensor(df_scaled, dtype=torch.float32)

    # Xá»­ lÃ½ height_values
    spatial_np = torch.tensor([h for h in df["height_values"].values], dtype=torch.float32).unsqueeze(1)

    # Dummy edge_index náº¿u khÃ´ng cÃ³ káº¿t ná»‘i
    num_nodes = len(df)
    edge_index = torch.empty((2, 0), dtype=torch.long)

    # === Predict ===
    with torch.no_grad():
        pred = model(spatial_np.to(device), scalar_tensor.to(device), edge_index.to(device))
        pred_np = pred.cpu().numpy().reshape(-1, 40, 40)
        df["pred_flood_values"] = [pred_np[i].tolist() for i in range(num_nodes)]

    # === TÃ­nh tá»•ng Ä‘á»™ ngáº­p (mean cÃ¡c giÃ¡ trá»‹ > 0) ===
    def mean_nonzero(arr):
        arr = np.array(arr)
        arr = arr[arr > 0]
        return arr.mean() if arr.size > 0 else 0.0

    df["pred_flood_score"] = df["pred_flood_values"].apply(mean_nonzero)

    # === In Top 10 vÃ¹ng cÃ³ Ä‘á»™ ngáº­p cao nháº¥t ===
    top10 = df_original.copy()
    top10["pred_flood_score"] = df["pred_flood_score"]
    cols = ["square_center_lat", "square_center_lon", "pred_flood_score"]
    if "big_square_id" in top10.columns:
        cols.insert(0, "big_square_id")

    top10_display = top10[cols].sort_values(by="pred_flood_score", ascending=False).head(10)

    print("ðŸŒŠ Top 10 khu vá»±c dá»± Ä‘oÃ¡n cÃ³ Ä‘á»™ ngáº­p cao nháº¥t:")
    print(top10_display)

    # === Xuáº¥t CSV sáº¡ch, giá»¯ láº¡i dá»¯ liá»‡u gá»‘c chÆ°a chuáº©n hÃ³a ===
    output_cols = [
        "big_square_id" if "big_square_id" in df_original.columns else None,
        "square_center_lat", "square_center_lon",
        "rainfall_3d", "rainfall_7d", "rainfall_1m",
        "permanent_water", "water_presence",
        "pred_flood_score"
    ]
    output_cols = [col for col in output_cols if col is not None]
    df_output = df_original.copy()
    df_output["pred_flood_score"] = df["pred_flood_score"]
    df_output.to_csv("data/final/yenbai_predictions_clean.csv", index=False)

    return df
